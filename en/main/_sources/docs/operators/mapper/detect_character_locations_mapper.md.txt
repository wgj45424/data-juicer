# detect_character_locations_mapper

Given an image and a list of main character names, extract the bounding boxes for each present character.

Detects and extracts bounding boxes for main characters in an image, this operator uses a YOLOE model to detect the presence of these characters. It then generates and refines bounding boxes for each detected character using a multimodal language model and an image-text matching filter. The final bounding boxes are stored in the metadata under 'main_character_locations_list'. The operator considers two bounding boxes as overlapping if their Intersection over Union (IoU) score exceeds a specified threshold. Additionally, it uses a matching score threshold to determine if a cropped image region matches the character's name. The operator utilizes a Hugging Face tokenizer and a BLIP model for image-text matching.

ç»™å®šä¸€å¼ å›¾åƒå’Œä¸»è¦è§’è‰²çš„åç§°åˆ—è¡¨ï¼Œæå–æ¯ä¸ªåœ¨åœºè§’è‰²çš„è¾¹ç•Œæ¡†ã€‚

æ£€æµ‹å¹¶æå–å›¾åƒä¸­ä¸»è¦è§’è‰²çš„è¾¹ç•Œæ¡†ï¼Œè¯¥ç®—å­ä½¿ç”¨YOLOEæ¨¡å‹æ£€æµ‹è¿™äº›è§’è‰²çš„å­˜åœ¨ã€‚ç„¶åï¼Œå®ƒä½¿ç”¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹å’Œå›¾æ–‡åŒ¹é…è¿‡æ»¤å™¨ç”Ÿæˆå¹¶ä¼˜åŒ–æ¯ä¸ªæ£€æµ‹åˆ°çš„è§’è‰²çš„è¾¹ç•Œæ¡†ã€‚æœ€ç»ˆçš„è¾¹ç•Œæ¡†å­˜å‚¨åœ¨å…ƒæ•°æ®çš„'main_character_locations_list'ä¸‹ã€‚å¦‚æœä¸¤ä¸ªè¾¹ç•Œæ¡†çš„äº¤å¹¶æ¯”ï¼ˆIoUï¼‰å¾—åˆ†è¶…è¿‡æŒ‡å®šé˜ˆå€¼ï¼Œåˆ™ç®—å­è®¤ä¸ºå®ƒä»¬æ˜¯é‡å çš„ã€‚æ­¤å¤–ï¼Œå®ƒä½¿ç”¨åŒ¹é…å¾—åˆ†é˜ˆå€¼æ¥ç¡®å®šè£å‰ªçš„å›¾åƒåŒºåŸŸæ˜¯å¦ä¸è§’è‰²åç§°åŒ¹é…ã€‚ç®—å­ä½¿ç”¨Hugging Faceçš„tokenizerå’ŒBLIPæ¨¡å‹è¿›è¡Œå›¾æ–‡åŒ¹é…ã€‚

Type ç®—å­ç±»å‹: **mapper**

Tags æ ‡ç­¾: gpu

## ğŸ”§ Parameter Configuration å‚æ•°é…ç½®
| name å‚æ•°å | type ç±»å‹ | default é»˜è®¤å€¼ | desc è¯´æ˜ |
|--------|------|--------|------|
| `mllm_mapper_args` | typing.Optional[typing.Dict] | `{}` | Arguments for multimodal language model mapper. Controls the generation of captions for bounding box regions. Default empty dict will use fixed values: max_new_tokens=256, temperature=0.2, top_p=None, num_beams=1, hf_model="llava-hf/llava-v1.6-vicuna-7b-hf". |
| `image_text_matching_filter_args` | typing.Optional[typing.Dict] | `{}` | Arguments for image-text matching filter. Controls the matching between cropped image regions and text descriptions. Default empty dict will use fixed values: min_score=0.1, max_score=1.0, hf_blip="Salesforce/blip-itm-base-coco", num_proc=1. |
| `yoloe_path` |  | `'yoloe-11l-seg.pt'` | The path to the YOLOE model. |
| `iou_threshold` |  | `0.7` | We consider two bounding boxes from different models to be overlapping when their IOU score is higher than the iou_threshold. |
| `matching_score_threshold` |  | `0.4` | If the matching score between the cropped image and the character's name exceeds the matching_score_threshold, they are considered a match. |
| `args` |  | `''` |  |
| `kwargs` |  | `''` |  |


## ğŸ”— related links ç›¸å…³é“¾æ¥
- [source code æºä»£ç ](../../../data_juicer/ops/mapper/detect_character_locations_mapper.py)
- [unit test å•å…ƒæµ‹è¯•](../../../tests/ops/mapper/test_detect_character_locations_mapper.py)
- [Return operator list è¿”å›ç®—å­åˆ—è¡¨](../../Operators.md)